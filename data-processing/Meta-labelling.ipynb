{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Reference:***\n",
    "> 1.\tLÃ³pez de Prado, Marcos. (2018).  Advances in Financial Machine Learning. 1st Edition. New Jersey: Wiley. pp.23-29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "import csv, os, time, glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.style.use('bmh')\n",
    "plt.rcParams['font.size'] = 9.5\n",
    "plt.rcParams['font.weight'] = 'medium'\n",
    "plt.rcParams['figure.figsize'] = 10,7\n",
    "blue, green, red, purple, gold, teal = sns.color_palette('colorblind', 6)\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import missingno as msno\n",
    "\n",
    "def create_data_set(raw_link,frq):\n",
    "    infp = raw_link\n",
    "    _data_= pd.read_csv(infp)#[['Date','Price']]\n",
    "    _data_= _data_.rename(columns={\"Price\":\"price\",\"Vol.\":\"volume\",\"Date\":'time_stamp'})\n",
    "    _data_=_data_[['time_stamp',\"price\",\"volume\"]].copy()\n",
    "    _data_[\"volume\"][_data_[\"volume\"]==\"-\"]=\"0K\"\n",
    "    _data_[\"mult\"] = 0\n",
    "    _data_[\"mult\"][_data_[\"volume\"].str.contains(\"K\")] = 1000\n",
    "    _data_[\"mult\"][_data_[\"volume\"].str.contains(\"M\")] = 1000000\n",
    "    _data_[\"volume\"] = _data_[\"volume\"].str.replace('K',\"\")\n",
    "    _data_[\"volume\"] = _data_[\"volume\"].str.replace('M',\"\")\n",
    "    _data_[\"volume\"]= _data_[\"volume\"].apply(pd.to_numeric)\n",
    "    _data_[\"volume\"] = _data_[\"volume\"]*_data_[\"mult\"]\n",
    "    del _data_[\"mult\"]\n",
    "\n",
    "    _data_['dollar_transaction'] = _data_['price'] * _data_['volume']\n",
    "    _data_=_data_.sort_values(by=['time_stamp'],ascending=[True])\n",
    "    _data_['time_stamp'] = pd.to_datetime(_data_['time_stamp'])\n",
    "    _data_.index = _data_['time_stamp']\n",
    "\n",
    "    _data_= _data_.resample(frq).agg({\"price\":'ohlc',\"volume\":'sum','dollar_transaction':'sum'})\n",
    "    _data_.columns = _data_.columns.droplevel()\n",
    "    #_data_= _data_[['close','volume','transaction']].rename(columns={'close':'price','volume':'v','transaction':'dv'})\n",
    "    _data_= _data_[['close','volume','dollar_transaction']]#.rename(columns={'close':'price','volume':'v','transaction':'dv'})\n",
    "    _data_['time_stamp'] = _data_.index\n",
    "    _data_= _data_.fillna(method='ffill')\n",
    "    return _data_\n",
    "\n",
    "def create_bar(dataframe, column_, units,vwap=False,price='close', volume ='volume',dollar_transaction='dollar_transaction'):\n",
    "    #print(column_)\n",
    "    _bars_ = dataframe.copy()\n",
    "    if column_ == 'time_stamp':\n",
    "        units_=units[0]\n",
    "        units_frequency=units[1]\n",
    "        _bars_= _bars_.resample(str(units_)+str(units_frequency), label='right').agg({price:'ohlc',volume:'sum',dollar_transaction:'sum'})\n",
    "        _bars_.columns = _bars_.columns.droplevel()\n",
    "        if vwap==True:\n",
    "            _bars_['vwap'] = _bars_[dollar_transaction]/_bars_[volume]\n",
    "        \n",
    "    else:\n",
    "        if column_ == 'id':\n",
    "            _bars_[column_] =1\n",
    "\n",
    "        _bars_['filter'] = _bars_[column_].cumsum()\n",
    "        _bars_['group']= 0\n",
    "        n = 0\n",
    "        _bars_['filter'] = _bars_['filter']/units\n",
    "        _bars_['filter'] = _bars_['filter'].astype(int)\n",
    "        _bars_['group']= _bars_['filter']\n",
    "        _bars_ = _bars_.groupby('group').agg({\"time_stamp\":\"last\",price:'ohlc',\"volume\":'sum','dollar_transaction':'sum'})\n",
    "        \n",
    "        _bars_.columns = _bars_.columns.droplevel()\n",
    "        if vwap==True:\n",
    "            _bars_['vwap'] = _bars_[dollar_transaction]/_bars_[volume]\n",
    "            _bars_ = _bars_.set_index('time_stamp')\n",
    "\n",
    "    _bars_ = _bars_.fillna(method='ffill')\n",
    "    return _bars_\n",
    "\n",
    "\n",
    "def getVol(close,span_=100,days = 1):\n",
    "    close = close.loc[~close.index.duplicated(keep='first')]\n",
    "    temp_=np.trim_zeros(close.index.searchsorted(close.index-pd.Timedelta(days=1)))\n",
    "    temp_=(pd.Series(close.index[temp_-1], index=close.index[close.shape[0]-temp_.shape[0]:]))   \n",
    "    temp_=close.loc[temp_.index]/close.loc[temp_.values].values-1\n",
    "    temp_=temp_.ewm(span=span_).std().rename('Volatility')\n",
    "    return temp_\n",
    "\n",
    "def getTEvents(gRaw, h):\n",
    "    tEvents, sPos, sNeg = [], 0, 0\n",
    "    diff = np.log(gRaw).diff().dropna()\n",
    "    for i in tqdm(diff.index[1:]):\n",
    "        try:\n",
    "            pos, neg = float(sPos+diff.loc[i]), float(sNeg+diff.loc[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(sPos+diff.loc[i], type(sPos+diff.loc[i]))\n",
    "            print(sNeg+diff.loc[i], type(sNeg+diff.loc[i]))\n",
    "            break\n",
    "        sPos, sNeg=max(0., pos), min(0., neg)\n",
    "        if sNeg<-h:\n",
    "            sNeg=0;tEvents.append(i)\n",
    "        elif sPos>h:\n",
    "            sPos=0;tEvents.append(i)\n",
    "    return pd.DatetimeIndex(tEvents)\n",
    "\n",
    "def dropLabels(events, minPct=.05):\n",
    "    while True:\n",
    "        df0=events['bin'].value_counts(normalize=True)\n",
    "        if df0.min()>minPct or df0.shape[0]<3:break\n",
    "        print('dropped label: ', df0.argmin(),df0.min())\n",
    "        events=events[events['bin']!=df0.argmin()]\n",
    "    return events\n",
    "\n",
    "def expandCall(kargs):\n",
    "    func=kargs['func']\n",
    "    del kargs['func']\n",
    "    out=func(**kargs)\n",
    "    return out\n",
    "\n",
    "def processJobs_(jobs):\n",
    "    out=[]\n",
    "    for job in jobs:\n",
    "        out_=expandCall(job)\n",
    "        out.append(out_)\n",
    "    return out\n",
    "\n",
    "def linParts(numAtoms,numThreads):\n",
    "    # partition of atoms with a single loop\n",
    "    parts=np.linspace(0,numAtoms,min(numThreads,numAtoms)+1)\n",
    "    parts=np.ceil(parts).astype(int)\n",
    "    return parts\n",
    "\n",
    "def mpPandasObj(func,pdObj,numThreads=24,mpBatches=1,linMols=True,**kargs):\n",
    "    '''\n",
    "    Parallelize jobs, return a dataframe or series\n",
    "    + func: function to be parallelized. Returns a DataFrame\n",
    "    + pdObj[0]: Name of argument used to pass the molecule\n",
    "    + pdObj[1]: List of atoms that will be grouped into molecules\n",
    "    + kwds: any other argument needed by func\n",
    "    \n",
    "    Example: df1=mpPandasObj(func,('molecule',df0.index),24,**kwds)\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    #if linMols:parts=linParts(len(argList[1]),numThreads*mpBatches)\n",
    "    #else:parts=nestedParts(len(argList[1]),numThreads*mpBatches)\n",
    "    if linMols:parts=linParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "    else:parts=nestedParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "    \n",
    "    jobs=[]\n",
    "    for i in range(1,len(parts)):\n",
    "        job={pdObj[0]:pdObj[1][parts[i-1]:parts[i]],'func':func}\n",
    "        job.update(kargs)\n",
    "        jobs.append(job)\n",
    "    if numThreads==1:out=processJobs_(jobs)\n",
    "    else: out=processJobs(jobs,numThreads=numThreads)\n",
    "    if isinstance(out[0],pd.DataFrame):df0=pd.DataFrame()\n",
    "    elif isinstance(out[0],pd.Series):df0=pd.Series()\n",
    "    else:return out\n",
    "    for i in out:df0=df0.append(i)\n",
    "    df0=df0.sort_index()\n",
    "    return df0\n",
    "\n",
    "def applyPtSlOnT1(close,events,ptSl,molecule):\n",
    "    # apply stop loss/profit taking, if it takes place before t1 (end of event)\n",
    "    events_=events.loc[molecule]\n",
    "    out=events_[['t1']].copy(deep=True)\n",
    "    if ptSl[0]>0: pt=ptSl[0]*events_['trgt']\n",
    "    else: pt=pd.Series(index=events.index) # NaNs\n",
    "    if ptSl[1]>0: sl=-ptSl[1]*events_['trgt']\n",
    "    else: sl=pd.Series(index=events.index) # NaNs\n",
    "    for loc,t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
    "        df0=close[loc:t1] # path prices\n",
    "        df0=(df0/close[loc]-1)*events_.at[loc,'side'] # path returns\n",
    "        out.loc[loc,'sl']=df0[df0<sl[loc]].index.min() # earliest stop loss\n",
    "        out.loc[loc,'pt']=df0[df0>pt[loc]].index.min() # earliest profit taking\n",
    "    return out\n",
    "\n",
    "def getEvents(close, tEvents, ptSl, trgt, minRet, numThreads, t1=False, side=None):\n",
    "    #1) get target\n",
    "    trgt=trgt.loc[tEvents]\n",
    "    trgt=trgt[trgt>minRet] # minRet\n",
    "    #2) get t1 (max holding period)\n",
    "    if t1 is False:t1=pd.Series(pd.NaT, index=tEvents)\n",
    "    #3) form events object, apply stop loss on t1\n",
    "    if side is None:side_,ptSl_=pd.Series(1.,index=trgt.index), [ptSl[0],ptSl[0]]\n",
    "    else: side_,ptSl_=side.loc[trgt.index],ptSl[:2]\n",
    "    events=(pd.concat({'t1':t1,'trgt':trgt,'side':side_}, axis=1)\n",
    "            .dropna(subset=['trgt']))\n",
    "    df0=mpPandasObj(func=applyPtSlOnT1,pdObj=('molecule',events.index),\n",
    "                    numThreads=numThreads,close=close,events=events,\n",
    "                    ptSl=ptSl_)\n",
    "    events['t1']=df0.dropna(how='all').min(axis=1) # pd.min ignores nan\n",
    "    if side is None:events=events.drop('side',axis=1)\n",
    "    return events\n",
    "\n",
    "def getBins(events, close):\n",
    "    '''\n",
    "    Compute event's outcome (including side information, if provided).\n",
    "    events is a DataFrame where:\n",
    "    -events.index is event's starttime\n",
    "    -events['t1'] is event's endtime\n",
    "    -events['trgt'] is event's target\n",
    "    -events['side'] (optional) implies the algo's position side\n",
    "    Case 1: ('side' not in events): bin in (-1,1) <-label by price action\n",
    "    Case 2: ('side' in events): bin in (0,1) <-label by pnl (meta-labeling)\n",
    "    '''\n",
    "    #1) prices aligned with events\n",
    "    events_=events.dropna(subset=['t1'])\n",
    "    px=events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px=close.reindex(px,method='bfill')\n",
    "    #2) create out object\n",
    "    out=pd.DataFrame(index=events_.index)\n",
    "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
    "    if 'side' in events_:out['ret']*=events_['side'] # meta-labeling\n",
    "    out['bin']=np.sign(out['ret'])\n",
    "    if 'side' in events_:out.loc[out['ret']<=0,'bin']=0 # meta-labeling\n",
    "    return out\n",
    "\n",
    "def addVerticalBarrier(tEvents, close, numDays=1):\n",
    "    t1=close.index.searchsorted(tEvents+pd.Timedelta(days=numDays))\n",
    "    t1=t1[t1<close.shape[0]]\n",
    "    t1=(pd.Series(close.index[t1],index=tEvents[:t1.shape[0]]))\n",
    "    return t1\n",
    "\n",
    "def getBinsNew(events, close, t1=None):\n",
    "    '''\n",
    "    Compute event's outcome (including side information, if provided).\n",
    "    events is a DataFrame where:\n",
    "    -events.index is event's starttime\n",
    "    -events['t1'] is event's endtime\n",
    "    -events['trgt'] is event's target\n",
    "    -events['side'] (optional) implies the algo's position side\n",
    "    -t1 is original vertical barrier series\n",
    "    Case 1: ('side' not in events): bin in (-1,1) <-label by price action\n",
    "    Case 2: ('side' in events): bin in (0,1) <-label by pnl (meta-labeling)\n",
    "    '''\n",
    "    #1) prices aligned with events\n",
    "    events_=events.dropna(subset=['t1'])\n",
    "    px=events_.index.union(events_['t1'].values).drop_duplicates()\n",
    "    px=close.reindex(px,method='bfill')\n",
    "    #2) create out object\n",
    "    out=pd.DataFrame(index=events_.index)\n",
    "    out['ret']=px.loc[events_['t1'].values].values/px.loc[events_.index]-1\n",
    "    if 'side' in events_:out['ret']*=events_['side'] # meta-labeling\n",
    "    out['bin']=np.sign(out['ret'])\n",
    "    \n",
    "    if 'side' not in events_:\n",
    "        # only applies when not meta-labeling\n",
    "        # to update bin to 0 when vertical barrier is touched, we need the original\n",
    "        # vertical barrier series since the events['t1'] is the time of first \n",
    "        # touch of any barrier and not the vertical barrier specifically. \n",
    "        # The index of the intersection of the vertical barrier values and the \n",
    "        # events['t1'] values indicate which bin labels needs to be turned to 0\n",
    "        vtouch_first_idx = events[events['t1'].isin(t1.values)].index\n",
    "        out.loc[vtouch_first_idx, 'bin'] = 0.\n",
    "    \n",
    "    if 'side' in events_:out.loc[out['ret']<=0,'bin']=0 # meta-labeling\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_up_cross(df):\n",
    "    crit1 = df.fast.shift(1) < df.slow.shift(1)\n",
    "    crit2 = df.fast > df.slow\n",
    "    return df.fast[(crit1) & (crit2)]\n",
    "\n",
    "def get_down_cross(df):\n",
    "    crit1 = df.fast.shift(1) > df.slow.shift(1)\n",
    "    crit2 = df.fast < df.slow\n",
    "    return df.fast[(crit1) & (crit2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../indices/\"\n",
    "data_dir = \"../indices_daily/\"\n",
    "\n",
    "for files in sorted(([s for s in glob.glob(data_dir +\"*.csv\") if \"csv\" in s]), key=os.path.getmtime):\n",
    "    #filem_name = 'Silver Futures (SIN9).csv'\n",
    "    #raw_link = (data_dir+filem_name)\n",
    "    raw_link = files\n",
    "    data = create_data_set(raw_link,'1D')\n",
    "\n",
    "    bars_ = create_bar(data,'time_stamp', [1,'D'],vwap=False,price= 'close', volume ='volume',dollar_transaction='dollar_transaction')\n",
    "\n",
    "    close = bars_.close.copy()\n",
    "    daily_Vol = getVol(close,span_=100,days = 1)\n",
    "\n",
    "#     f,ax=plt.subplots()\n",
    "#     daily_Vol.plot(ax=ax)\n",
    "#     ax.axhline(daily_Vol.mean(),ls='--',color='r')\n",
    "\n",
    "\n",
    "    h=daily_Vol.mean()\n",
    "\n",
    "    # tEvents to find the time at which A vertical Side can be kept for Triple barrier\n",
    "    tEvents = getTEvents(close,h=h)\n",
    "    t1 = addVerticalBarrier(tEvents, close, numDays=1)\n",
    "\n",
    "    ptsl = [1,1]\n",
    "    target=daily_Vol\n",
    "    # select minRet\n",
    "    minRet = 0.025 # 3% return\n",
    "    cpus = 1\n",
    "    events = getEvents(close,tEvents,ptsl,target,minRet,cpus,t1=t1)\n",
    "\n",
    "    labels = getBins(events, close)\n",
    "\n",
    "    clean_labels = dropLabels(labels)\n",
    "\n",
    "    clean_labels = clean_labels.rename(columns={'ret':'triple_ret','bin':'triple_bin'})\n",
    "\n",
    "\n",
    "\n",
    "    fast_window = 3\n",
    "    slow_window = 7\n",
    "\n",
    "    close_df = (pd.DataFrame().assign(price=close).assign(fast=close.ewm(fast_window).mean())\n",
    "                .assign(slow=close.ewm(slow_window).mean()))\n",
    "\n",
    "\n",
    "    up = get_up_cross(close_df)\n",
    "    down = get_down_cross(close_df)\n",
    "\n",
    "#     f, ax = plt.subplots(figsize=(11,8))\n",
    "#     close_df.loc['2014':].plot(ax=ax, alpha=.5)\n",
    "#     up.loc['2014':].plot(ax=ax,ls='',marker='^', markersize=7,\n",
    "#                          alpha=0.75, label='upcross', color='g')\n",
    "#     down.loc['2014':].plot(ax=ax,ls='',marker='v', markersize=7, \n",
    "#                            alpha=0.75, label='downcross', color='r')\n",
    "#     ax.legend()\n",
    "\n",
    "    side_up = pd.Series(1, index=up.index)\n",
    "    side_down = pd.Series(-1, index=down.index)\n",
    "    side = pd.concat([side_up,side_down]).sort_index()\n",
    "\n",
    "    minRet = 0.025\n",
    "    ptsl=[1,2]\n",
    "\n",
    "    monVol = (close_df['price']/close_df['price'].shift(1)-1).ewm(span=10).std()\n",
    "    tEvents = getTEvents(close_df['price'],h=monVol.mean())\n",
    "    t1 = addVerticalBarrier(tEvents, close_df['price'], numDays=1)\n",
    "\n",
    "    ma_events = getEvents(close_df['price'],tEvents,ptsl,target,minRet,cpus,\n",
    "                          t1=t1,side=side)\n",
    "\n",
    "\n",
    "    ma_events.side.value_counts()\n",
    "    ma_side = ma_events.dropna().side\n",
    "    ma_bins = getBinsNew(ma_events,close_df['price'], t1).dropna()\n",
    "    labelling = pd.merge_asof(ma_bins, side.to_frame().rename(columns={0:'side'}),\n",
    "                       left_index=True, right_index=True, direction='forward')\n",
    "\n",
    "\n",
    "    labelling = labelling.rename(columns={'ret':'met_ret','bin':'met_bin','side':'met_side'})\n",
    "\n",
    "    temp_data = pd.concat([data,clean_labels,labelling],axis=1)\n",
    "    del temp_data['time_stamp']\n",
    "\n",
    "    temp_data.to_csv(files.replace('indices_daily/','indices_daily/processed/'))\n",
    "\n",
    "    shutil.move(files, files.replace('indices_daily/','indices_daily/raw/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.7)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
